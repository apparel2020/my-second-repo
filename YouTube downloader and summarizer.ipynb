{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyORJESC+YWOQqkp6aNwj59X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apparel2020/my-second-repo/blob/main/YouTube%20downloader%20and%20summarizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YouTube Audio Transcription and Summarization using Open Source Models\n",
        "# For Google Colab Free Tier - With YouTube Bot Detection Fix\n",
        "\n",
        "# Install required packages\n",
        "!pip install yt-dlp transformers sentencepiece datasets accelerate torch bitsandbytes peft optimum\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import re\n",
        "import torch\n",
        "import subprocess\n",
        "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
        "import whisper\n",
        "\n",
        "# Function to download YouTube audio using yt-dlp (more reliable than pytubefix)\n",
        "def youtube_audio_downloader(link):\n",
        "    if not link or ('youtube.com' not in link and 'youtu.be' not in link):\n",
        "        print('Invalid YouTube link!')\n",
        "        return False\n",
        "\n",
        "    print('Downloading the audio stream...')\n",
        "\n",
        "    # Create output filename based on current timestamp\n",
        "    import time\n",
        "    output_filename = f\"audio_{int(time.time())}.mp3\"\n",
        "\n",
        "    # Use yt-dlp which has better anti-bot-detection capabilities\n",
        "    command = [\n",
        "        'yt-dlp',\n",
        "        '-x',  # Extract audio\n",
        "        '--audio-format', 'mp3',  # Convert to mp3\n",
        "        '--audio-quality', '0',  # Best quality\n",
        "        '-o', output_filename,  # Output filename\n",
        "        link  # YouTube URL\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        subprocess.run(command, check=True)\n",
        "        if os.path.exists(output_filename):\n",
        "            print('Download completed successfully!')\n",
        "            return output_filename\n",
        "        else:\n",
        "            print('Error: Download completed but file not found!')\n",
        "            return False\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f'Error downloading the file: {e}')\n",
        "        # Try alternate method if first method fails\n",
        "        try:\n",
        "            print('Trying alternate download method...')\n",
        "            alt_command = [\n",
        "                'yt-dlp',\n",
        "                '-f', 'bestaudio',  # Best audio format available\n",
        "                '--extract-audio',\n",
        "                '--audio-format', 'mp3',\n",
        "                '--audio-quality', '0',\n",
        "                '-o', output_filename,\n",
        "                '--no-check-certificates',  # Skip HTTPS certificate validation\n",
        "                '--user-agent', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36',\n",
        "                link\n",
        "            ]\n",
        "            subprocess.run(alt_command, check=True)\n",
        "            if os.path.exists(output_filename):\n",
        "                print('Alternate download method succeeded!')\n",
        "                return output_filename\n",
        "            else:\n",
        "                print('Error: Alternate download completed but file not found!')\n",
        "                return False\n",
        "        except subprocess.CalledProcessError as e2:\n",
        "            print(f'Error with alternate download method: {e2}')\n",
        "            return False\n",
        "\n",
        "# Function to transcribe audio using Whisper (open source version)\n",
        "def transcribe(audio_file, not_english=False):\n",
        "    if not os.path.exists(audio_file):\n",
        "        print('Audio file does not exist!')\n",
        "        return False\n",
        "\n",
        "    print('Loading Whisper model...')\n",
        "    # Use a smaller model to fit within Colab's free tier memory constraints\n",
        "    model = whisper.load_model(\"base\")\n",
        "\n",
        "    print('Starting transcription...')\n",
        "    if not_english:\n",
        "        # Translate to English\n",
        "        result = model.transcribe(audio_file, task=\"translate\")\n",
        "    else:\n",
        "        # Just transcribe\n",
        "        result = model.transcribe(audio_file)\n",
        "    print('Transcription completed!')\n",
        "\n",
        "    name, extension = os.path.splitext(audio_file)\n",
        "    transcript_filename = f'transcript-{name}.txt'\n",
        "    with open(transcript_filename, 'w', encoding='utf-8') as f:\n",
        "        f.write(result[\"text\"])\n",
        "\n",
        "    print(f'Transcript saved to {transcript_filename}')\n",
        "    return transcript_filename\n",
        "\n",
        "# Function to summarize text using an open source LLM (T5 version)\n",
        "def summarize(transcript_filename):\n",
        "    if not os.path.exists(transcript_filename):\n",
        "        print('The transcript file does not exist!')\n",
        "        return False\n",
        "\n",
        "    with open(transcript_filename, 'r', encoding='utf-8') as f:\n",
        "        transcript = f.read()\n",
        "\n",
        "    print('Loading summarization model (FLAN-T5)...')\n",
        "    # Use FLAN-T5 for summarization - efficient and works well on Colab's free tier\n",
        "    device = 0 if torch.cuda.is_available() else -1\n",
        "    print(f\"Using device: {'CUDA' if device == 0 else 'CPU'}\")\n",
        "\n",
        "    summarizer = pipeline(\n",
        "        \"summarization\",\n",
        "        model=\"google/flan-t5-base\",\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    # Handle long transcripts by splitting into chunks\n",
        "    max_input_length = 500  # T5 has limited context window\n",
        "\n",
        "    if len(transcript) <= max_input_length:\n",
        "        chunks = [transcript]\n",
        "    else:\n",
        "        # Split by sentences to preserve meaning\n",
        "        import re\n",
        "        sentences = re.split(r'(?<=[.!?])\\s+', transcript)\n",
        "        chunks = []\n",
        "        current_chunk = \"\"\n",
        "\n",
        "        for sentence in sentences:\n",
        "            if len(current_chunk) + len(sentence) < max_input_length:\n",
        "                current_chunk += sentence + \" \"\n",
        "            else:\n",
        "                chunks.append(current_chunk.strip())\n",
        "                current_chunk = sentence + \" \"\n",
        "\n",
        "        if current_chunk:\n",
        "            chunks.append(current_chunk.strip())\n",
        "\n",
        "    print(f'Processing transcript in {len(chunks)} chunks...')\n",
        "\n",
        "    # Process each chunk\n",
        "    summary_chunks = []\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        print(f'Summarizing chunk {i+1}/{len(chunks)}...')\n",
        "\n",
        "        # Add summarization prompt\n",
        "        prompt = f\"\"\"Summarize this text: {chunk}\"\"\"\n",
        "\n",
        "        summary_part = summarizer(prompt, max_length=150, min_length=30)\n",
        "        summary_chunks.append(summary_part[0]['summary_text'])\n",
        "\n",
        "    # Combine all summaries\n",
        "    if len(summary_chunks) > 1:\n",
        "        print('Generating final summary from all chunks...')\n",
        "        combined_summary = \" \".join(summary_chunks)\n",
        "        final_prompt = f\"\"\"Create a coherent summary with a title, introduction,\n",
        "        key points as bullet points, and a conclusion from this text: {combined_summary}\"\"\"\n",
        "\n",
        "        final_summary = summarizer(final_prompt, max_length=300, min_length=100)[0]['summary_text']\n",
        "    else:\n",
        "        final_summary = summary_chunks[0]\n",
        "\n",
        "    print('Summarization completed!')\n",
        "    return final_summary\n",
        "\n",
        "# Alternative summarization function using a different open source model\n",
        "def summarize_with_llama(transcript_filename):\n",
        "    \"\"\"Use a Llama-based model for summarization. This is more powerful but may require\n",
        "    more resources than the T5 model.\"\"\"\n",
        "\n",
        "    if not os.path.exists(transcript_filename):\n",
        "        print('The transcript file does not exist!')\n",
        "        return False\n",
        "\n",
        "    print('Loading TinyLlama for summarization...')\n",
        "    # Use TinyLlama which is smaller and can run on Colab's free tier\n",
        "    model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
        "\n",
        "    # Load in 4-bit to save memory\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        torch_dtype=torch.float16,\n",
        "        load_in_4bit=True,\n",
        "        device_map=\"auto\"\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    with open(transcript_filename, 'r', encoding='utf-8') as f:\n",
        "        transcript = f.read()\n",
        "\n",
        "    # Calculate available context window\n",
        "    max_input_length = 2048  # Define maximum context length\n",
        "\n",
        "    # Handle long transcripts\n",
        "    if len(transcript) > max_input_length - 500:  # Reserve 500 tokens for the prompt\n",
        "        print(f\"Transcript too long ({len(transcript)} chars), truncating to fit context window\")\n",
        "        transcript = transcript[:max_input_length - 500]\n",
        "\n",
        "    # Create a prompt with instructions\n",
        "    prompt = f\"\"\"<|system|>\n",
        "You are a helpful AI assistant that creates concise summaries.\n",
        "<|user|>\n",
        "Create a summary of the following text.\n",
        "Text: {transcript}\n",
        "\n",
        "Add a title to the summary.\n",
        "Your summary should be informative and factual, covering the most important aspects of the topic.\n",
        "Start your summary with an INTRODUCTION PARAGRAPH that gives an overview of the topic FOLLOWED by BULLET POINTS if possible AND end the summary with a CONCLUSION PHRASE.\n",
        "<|assistant|>\n",
        "\"\"\"\n",
        "\n",
        "    print('Generating summary...')\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    outputs = model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_new_tokens=500,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        do_sample=True\n",
        "    )\n",
        "\n",
        "    summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    # Extract only the assistant's response\n",
        "    summary = summary.split(\"<|assistant|>\")[-1].strip()\n",
        "\n",
        "    print('Summary generation completed!')\n",
        "    return summary\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\"*50)\n",
        "    print(\"YouTube Transcription and Summarization Tool\")\n",
        "    print(\"(Using Open Source Models on Google Colab Free Tier)\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    # Ask for YouTube link\n",
        "    link = input('Enter the YouTube video URL: ')\n",
        "\n",
        "    # Download audio\n",
        "    mp3_file = youtube_audio_downloader(link)\n",
        "    if not mp3_file:\n",
        "        print(\"Failed to download audio. Please try a different video or check the URL.\")\n",
        "        exit()\n",
        "\n",
        "    # Ask if the content is not in English\n",
        "    not_english_input = input('Is the content not in English? (y/n): ').lower()\n",
        "    not_english = not_english_input.startswith('y')\n",
        "\n",
        "    # Transcribe\n",
        "    transcript_file = transcribe(mp3_file, not_english=not_english)\n",
        "    if not transcript_file:\n",
        "        print(\"Failed to transcribe audio.\")\n",
        "        exit()\n",
        "\n",
        "    # Choose summarization method based on available resources\n",
        "    print(\"\\nChoose summarization method:\")\n",
        "    print(\"1. FLAN-T5 (faster, less RAM usage)\")\n",
        "    print(\"2. TinyLlama (better quality, more RAM required)\")\n",
        "\n",
        "    model_choice = input('Enter your choice (1 or 2): ')\n",
        "\n",
        "    try:\n",
        "        if model_choice == '2':\n",
        "            summary = summarize_with_llama(transcript_file)\n",
        "        else:\n",
        "            summary = summarize(transcript_file)\n",
        "\n",
        "        # Save summary to file\n",
        "        summary_file = f\"summary_{os.path.basename(transcript_file)}\"\n",
        "        with open(summary_file, 'w', encoding='utf-8') as f:\n",
        "            f.write(summary)\n",
        "\n",
        "        print('\\n\\nSUMMARY:')\n",
        "        print('='*50)\n",
        "        print(summary)\n",
        "        print('='*50)\n",
        "        print(f\"\\nSummary saved to {summary_file}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during summarization: {e}\")\n",
        "        print(\"If you selected TinyLlama and encountered an error, try FLAN-T5 instead (it requires less RAM).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3TedpaoBSOi",
        "outputId": "d7c76205-a1bc-4667-e415-a8baa2e6bdf5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: yt-dlp in /usr/local/lib/python3.11/dist-packages (2025.4.30)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
            "Requirement already satisfied: optimum in /usr/local/lib/python3.11/dist-packages (1.24.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-568hd2q6\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-568hd2q6\n",
            "  Resolved https://github.com/openai/whisper.git to commit 517a43ecd132a2089d85f4ebc044728a71d49f6e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (10.7.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.0.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (0.9.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (4.67.1)\n",
            "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.11/dist-packages (from openai-whisper==20240930) (3.2.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (12.4.127)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
            "==================================================\n",
            "YouTube Transcription and Summarization Tool\n",
            "(Using Open Source Models on Google Colab Free Tier)\n",
            "==================================================\n",
            "Enter the YouTube video URL: https://www.youtube.com/watch?v=CBYhVcO4WgI&t=308s&pp=ygUSc3RhcnR1cCBzYW0gYWx0bWFu\n",
            "Downloading the audio stream...\n",
            "Download completed successfully!\n",
            "Is the content not in English? (y/n): y\n",
            "Loading Whisper model...\n",
            "Starting transcription...\n",
            "Transcription completed!\n",
            "Transcript saved to transcript-audio_1746612046.txt\n",
            "\n",
            "Choose summarization method:\n",
            "1. FLAN-T5 (faster, less RAM usage)\n",
            "2. TinyLlama (better quality, more RAM required)\n",
            "Enter your choice (1 or 2): 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading TinyLlama for summarization...\n",
            "Transcript too long (48608 chars), truncating to fit context window\n",
            "Generating summary...\n",
            "Summary generation completed!\n",
            "\n",
            "\n",
            "SUMMARY:\n",
            "==================================================\n",
            "Welcome to CS1-83B, the nine-year-old startup incubator that teaches 17 classes and offers advice to 720 companies. The guest speakers are experts in the creation of billion-dollar companies, and the advice is based on practical experience.\n",
            "==================================================\n",
            "\n",
            "Summary saved to summary_transcript-audio_1746612046.txt\n"
          ]
        }
      ]
    }
  ]
}